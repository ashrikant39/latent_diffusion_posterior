no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/condabin/conda
no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/bin/conda
no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/bin/conda-env
no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/bin/activate
no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/bin/deactivate
no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/etc/profile.d/conda.sh
no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/etc/fish/conf.d/conda.fish
no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/shell/condabin/Conda.psm1
no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/shell/condabin/conda-hook.ps1
no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages/xontrib/conda.xsh
no change     /sw/pkgs/arc/python3.9-anaconda/2021.11/etc/profile.d/conda.csh
no change     /home/ashri/.bashrc
No action taken.
Loading model from /nfs/turbo/coe-hunseok/ashri/lsun_data/loggings/jscc_models_finetune/snr_0/2023-06-30T10-45-32_jscc_64x64x3/checkpoints/last.ckpt
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 3, 64, 64) = 12288 dimensions.
making attention of type 'vanilla' with 512 in_channels
Loading model from models/ldm/lsun_beds256/autoencoder.ckpt...
Total Params: 55298182
Total Trainable Params: 32961286
  0%|          | 0/75 [00:00<?, ?it/s]  1%|▏         | 1/75 [00:10<12:23, 10.04s/it]  3%|▎         | 2/75 [00:18<10:58,  9.02s/it]  4%|▍         | 3/75 [00:26<10:15,  8.54s/it]  5%|▌         | 4/75 [00:34<10:00,  8.46s/it]  7%|▋         | 5/75 [00:42<09:38,  8.26s/it]  8%|▊         | 6/75 [00:50<09:29,  8.25s/it]  9%|▉         | 7/75 [00:58<09:06,  8.04s/it] 11%|█         | 8/75 [01:06<08:54,  7.98s/it] 12%|█▏        | 9/75 [01:14<08:53,  8.08s/it] 13%|█▎        | 10/75 [01:22<08:43,  8.05s/it] 15%|█▍        | 11/75 [01:30<08:39,  8.12s/it] 16%|█▌        | 12/75 [01:38<08:28,  8.07s/it] 17%|█▋        | 13/75 [01:47<08:24,  8.14s/it] 19%|█▊        | 14/75 [01:55<08:13,  8.09s/it] 20%|██        | 15/75 [02:03<08:09,  8.16s/it] 21%|██▏       | 16/75 [02:11<07:57,  8.09s/it] 23%|██▎       | 17/75 [02:19<07:53,  8.17s/it] 24%|██▍       | 18/75 [02:28<07:48,  8.23s/it] 25%|██▌       | 19/75 [02:35<07:34,  8.12s/it] 27%|██▋       | 20/75 [02:44<07:30,  8.19s/it] 28%|██▊       | 21/75 [02:52<07:24,  8.23s/it] 29%|██▉       | 22/75 [03:00<07:05,  8.03s/it] 31%|███       | 23/75 [03:08<07:01,  8.11s/it] 32%|███▏      | 24/75 [03:16<06:50,  8.05s/it] 33%|███▎      | 25/75 [03:24<06:40,  8.02s/it] 35%|███▍      | 26/75 [03:32<06:36,  8.09s/it] 36%|███▌      | 27/75 [03:40<06:26,  8.04s/it] 37%|███▋      | 28/75 [03:48<06:21,  8.12s/it] 39%|███▊      | 29/75 [03:56<06:11,  8.07s/it] 40%|████      | 30/75 [04:05<06:08,  8.18s/it] 41%|████▏     | 31/75 [04:12<05:51,  7.98s/it] 43%|████▎     | 32/75 [04:20<05:41,  7.95s/it] 44%|████▍     | 33/75 [04:28<05:28,  7.82s/it] 45%|████▌     | 34/75 [04:35<05:20,  7.82s/it] 47%|████▋     | 35/75 [04:44<05:19,  7.98s/it] 48%|████▊     | 36/75 [04:52<05:14,  8.08s/it] 49%|████▉     | 37/75 [05:00<05:00,  7.90s/it] 51%|█████     | 38/75 [05:07<04:48,  7.80s/it] 52%|█████▏    | 39/75 [05:15<04:41,  7.82s/it] 52%|█████▏    | 39/75 [05:16<04:52,  8.11s/it]
Traceback (most recent call last):
  File "denoising.py", line 183, in <module>
    reconstructed = deep_jscc_testing(jscc_model, images, SNR_DB)
  File "denoising.py", line 26, in deep_jscc_testing
    noisy_latent = model.encode_through_channel(images, snr_db)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 326, in encode_through_channel
    latent_signal = self.encode(x)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 280, in encode
    h = self.encoder(x)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 453, in forward
    h = self.mid.block_2(h, temb)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 130, in forward
    h = self.norm2(h)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/normalization.py", line 245, in forward
    return F.group_norm(
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/functional.py", line 2111, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps,
RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 44.40 GiB total capacity; 43.08 GiB already allocated; 5.25 MiB free; 43.17 GiB reserved in total by PyTorch)
Loading model from /nfs/turbo/coe-hunseok/ashri/lsun_data/loggings/jscc_models_finetune/snr_0/2023-06-30T10-45-32_jscc_64x64x3/checkpoints/last.ckpt
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 3, 64, 64) = 12288 dimensions.
making attention of type 'vanilla' with 512 in_channels
Loading model from models/ldm/lsun_beds256/autoencoder.ckpt...
Total Params: 55298182
Total Trainable Params: 32961286
  0%|          | 0/75 [00:00<?, ?it/s]  1%|▏         | 1/75 [00:10<12:32, 10.16s/it]  3%|▎         | 2/75 [00:18<10:43,  8.82s/it]  4%|▍         | 3/75 [00:25<10:03,  8.38s/it]  5%|▌         | 4/75 [00:34<09:53,  8.37s/it]  7%|▋         | 5/75 [00:42<09:34,  8.20s/it]  8%|▊         | 6/75 [00:50<09:26,  8.21s/it]  9%|▉         | 7/75 [00:58<09:05,  8.02s/it] 11%|█         | 8/75 [01:05<08:54,  7.97s/it] 12%|█▏        | 9/75 [01:13<08:45,  7.96s/it] 13%|█▎        | 10/75 [01:21<08:35,  7.93s/it] 15%|█▍        | 11/75 [01:29<08:28,  7.94s/it] 16%|█▌        | 12/75 [01:37<08:19,  7.93s/it] 17%|█▋        | 13/75 [01:45<08:12,  7.94s/it] 19%|█▊        | 14/75 [01:53<08:04,  7.94s/it] 20%|██        | 15/75 [02:01<08:02,  8.03s/it] 21%|██▏       | 16/75 [02:09<07:45,  7.89s/it] 23%|██▎       | 17/75 [02:17<07:37,  7.89s/it] 24%|██▍       | 18/75 [02:25<07:37,  8.02s/it] 25%|██▌       | 19/75 [02:33<07:27,  7.99s/it] 27%|██▋       | 20/75 [02:41<07:18,  7.98s/it] 28%|██▊       | 21/75 [02:49<07:15,  8.06s/it] 29%|██▉       | 22/75 [02:57<07:00,  7.93s/it] 31%|███       | 23/75 [03:05<06:51,  7.91s/it] 32%|███▏      | 24/75 [03:12<06:43,  7.91s/it] 33%|███▎      | 25/75 [03:20<06:34,  7.90s/it] 35%|███▍      | 26/75 [03:28<06:27,  7.91s/it] 36%|███▌      | 27/75 [03:37<06:26,  8.06s/it] 37%|███▋      | 28/75 [03:45<06:17,  8.03s/it] 39%|███▊      | 29/75 [03:53<06:08,  8.00s/it] 40%|████      | 30/75 [04:01<05:58,  7.98s/it] 41%|████▏     | 31/75 [04:08<05:50,  7.96s/it] 43%|████▎     | 32/75 [04:16<05:41,  7.94s/it] 44%|████▍     | 33/75 [04:24<05:33,  7.94s/it] 45%|████▌     | 34/75 [04:32<05:24,  7.91s/it] 47%|████▋     | 35/75 [04:40<05:11,  7.79s/it] 48%|████▊     | 36/75 [04:48<05:08,  7.92s/it] 49%|████▉     | 37/75 [04:55<04:56,  7.81s/it] 51%|█████     | 38/75 [05:04<04:52,  7.92s/it] 52%|█████▏    | 39/75 [05:11<04:41,  7.82s/it] 52%|█████▏    | 39/75 [05:12<04:48,  8.00s/it]
Traceback (most recent call last):
  File "denoising.py", line 183, in <module>
    reconstructed = deep_jscc_testing(jscc_model, images, SNR_DB)
  File "denoising.py", line 26, in deep_jscc_testing
    noisy_latent = model.encode_through_channel(images, snr_db)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 326, in encode_through_channel
    latent_signal = self.encode(x)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 280, in encode
    h = self.encoder(x)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 453, in forward
    h = self.mid.block_2(h, temb)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 130, in forward
    h = self.norm2(h)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/normalization.py", line 245, in forward
    return F.group_norm(
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/functional.py", line 2111, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps,
RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 44.40 GiB total capacity; 43.08 GiB already allocated; 5.25 MiB free; 43.17 GiB reserved in total by PyTorch)
Loading model from /nfs/turbo/coe-hunseok/ashri/lsun_data/loggings/jscc_models_finetune/snr_0/2023-06-30T10-45-32_jscc_64x64x3/checkpoints/last.ckpt
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 3, 64, 64) = 12288 dimensions.
making attention of type 'vanilla' with 512 in_channels
Loading model from models/ldm/lsun_beds256/autoencoder.ckpt...
Total Params: 55298182
Total Trainable Params: 32961286
  0%|          | 0/75 [00:00<?, ?it/s]  1%|▏         | 1/75 [00:10<12:29, 10.13s/it]  3%|▎         | 2/75 [00:18<10:43,  8.82s/it]  4%|▍         | 3/75 [00:25<10:03,  8.38s/it]  5%|▌         | 4/75 [00:33<09:43,  8.22s/it]  7%|▋         | 5/75 [00:41<09:26,  8.09s/it]  8%|▊         | 6/75 [00:49<09:21,  8.14s/it]  9%|▉         | 7/75 [00:57<09:01,  7.96s/it] 11%|█         | 8/75 [01:05<08:52,  7.95s/it] 12%|█▏        | 9/75 [01:13<08:52,  8.07s/it] 13%|█▎        | 10/75 [01:21<08:40,  8.02s/it] 15%|█▍        | 11/75 [01:30<08:39,  8.11s/it] 16%|█▌        | 12/75 [01:37<08:27,  8.05s/it] 17%|█▋        | 13/75 [01:45<08:17,  8.02s/it] 19%|█▊        | 14/75 [01:53<08:06,  7.98s/it] 20%|██        | 15/75 [02:02<08:05,  8.10s/it] 21%|██▏       | 16/75 [02:10<08:02,  8.17s/it] 23%|██▎       | 17/75 [02:18<07:57,  8.22s/it] 24%|██▍       | 18/75 [02:26<07:44,  8.15s/it] 25%|██▌       | 19/75 [02:34<07:31,  8.07s/it] 27%|██▋       | 20/75 [02:43<07:27,  8.14s/it] 28%|██▊       | 21/75 [02:51<07:21,  8.18s/it] 29%|██▉       | 22/75 [02:59<07:10,  8.12s/it] 31%|███       | 23/75 [03:07<06:59,  8.07s/it] 32%|███▏      | 24/75 [03:15<06:55,  8.15s/it] 33%|███▎      | 25/75 [03:23<06:43,  8.07s/it] 35%|███▍      | 26/75 [03:31<06:33,  8.03s/it] 36%|███▌      | 27/75 [03:39<06:23,  7.99s/it] 37%|███▋      | 28/75 [03:47<06:19,  8.08s/it] 39%|███▊      | 29/75 [03:55<06:09,  8.03s/it] 40%|████      | 30/75 [04:03<06:00,  8.00s/it] 41%|████▏     | 31/75 [04:11<05:56,  8.10s/it] 43%|████▎     | 32/75 [04:19<05:45,  8.04s/it] 44%|████▍     | 33/75 [04:27<05:35,  7.98s/it] 45%|████▌     | 34/75 [04:35<05:21,  7.85s/it] 47%|████▋     | 35/75 [04:42<05:14,  7.86s/it] 48%|████▊     | 36/75 [04:51<05:11,  7.98s/it] 49%|████▉     | 37/75 [04:58<04:58,  7.86s/it] 51%|█████     | 38/75 [05:06<04:51,  7.88s/it] 52%|█████▏    | 39/75 [05:14<04:43,  7.88s/it] 52%|█████▏    | 39/75 [05:14<04:50,  8.08s/it]
Traceback (most recent call last):
  File "denoising.py", line 183, in <module>
    reconstructed = deep_jscc_testing(jscc_model, images, SNR_DB)
  File "denoising.py", line 26, in deep_jscc_testing
    noisy_latent = model.encode_through_channel(images, snr_db)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 326, in encode_through_channel
    latent_signal = self.encode(x)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 280, in encode
    h = self.encoder(x)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 453, in forward
    h = self.mid.block_2(h, temb)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 130, in forward
    h = self.norm2(h)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/normalization.py", line 245, in forward
    return F.group_norm(
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/functional.py", line 2111, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps,
RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 44.40 GiB total capacity; 43.08 GiB already allocated; 5.25 MiB free; 43.17 GiB reserved in total by PyTorch)
Loading model from /nfs/turbo/coe-hunseok/ashri/lsun_data/loggings/jscc_models_finetune/snr_0/2023-06-30T10-45-32_jscc_64x64x3/checkpoints/last.ckpt
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 3, 64, 64) = 12288 dimensions.
making attention of type 'vanilla' with 512 in_channels
Loading model from models/ldm/lsun_beds256/autoencoder.ckpt...
Total Params: 55298182
Total Trainable Params: 32961286
  0%|          | 0/75 [00:00<?, ?it/s]  1%|▏         | 1/75 [00:10<13:01, 10.56s/it]  3%|▎         | 2/75 [00:18<10:39,  8.76s/it]  4%|▍         | 3/75 [00:25<10:01,  8.35s/it]  5%|▌         | 4/75 [00:34<09:49,  8.30s/it]  7%|▋         | 5/75 [00:41<09:22,  8.04s/it]  8%|▊         | 6/75 [00:50<09:20,  8.12s/it]  9%|▉         | 7/75 [00:57<09:08,  8.06s/it] 11%|█         | 8/75 [01:05<08:58,  8.03s/it] 12%|█▏        | 9/75 [01:14<08:55,  8.12s/it] 13%|█▎        | 10/75 [01:22<08:44,  8.06s/it] 15%|█▍        | 11/75 [01:30<08:32,  8.01s/it] 16%|█▌        | 12/75 [01:37<08:23,  7.99s/it] 17%|█▋        | 13/75 [01:46<08:21,  8.09s/it] 19%|█▊        | 14/75 [01:54<08:10,  8.05s/it] 20%|██        | 15/75 [02:02<08:01,  8.02s/it] 21%|██▏       | 16/75 [02:10<07:59,  8.12s/it] 23%|██▎       | 17/75 [02:18<07:47,  8.07s/it] 24%|██▍       | 18/75 [02:26<07:43,  8.13s/it] 25%|██▌       | 19/75 [02:34<07:32,  8.07s/it] 27%|██▋       | 20/75 [02:45<08:03,  8.79s/it] 28%|██▊       | 21/75 [02:53<07:41,  8.55s/it] 29%|██▉       | 22/75 [03:00<07:18,  8.27s/it] 31%|███       | 23/75 [03:08<07:05,  8.18s/it] 32%|███▏      | 24/75 [03:17<06:58,  8.21s/it] 33%|███▎      | 25/75 [03:24<06:46,  8.12s/it] 35%|███▍      | 26/75 [03:32<06:35,  8.07s/it] 36%|███▌      | 27/75 [03:40<06:25,  8.03s/it] 37%|███▋      | 28/75 [03:48<06:16,  8.00s/it] 39%|███▊      | 29/75 [03:56<06:06,  7.97s/it] 40%|████      | 30/75 [04:04<05:58,  7.96s/it] 41%|████▏     | 31/75 [04:12<05:55,  8.07s/it] 43%|████▎     | 32/75 [04:20<05:44,  8.01s/it] 44%|████▍     | 33/75 [04:28<05:29,  7.85s/it] 45%|████▌     | 34/75 [04:36<05:21,  7.85s/it] 47%|████▋     | 35/75 [04:44<05:15,  7.88s/it] 48%|████▊     | 36/75 [04:52<05:11,  7.99s/it] 49%|████▉     | 37/75 [04:59<04:58,  7.86s/it] 51%|█████     | 38/75 [05:07<04:51,  7.88s/it] 52%|█████▏    | 39/75 [05:15<04:43,  7.87s/it] 52%|█████▏    | 39/75 [05:16<04:51,  8.11s/it]
Traceback (most recent call last):
  File "denoising.py", line 183, in <module>
    reconstructed = deep_jscc_testing(jscc_model, images, SNR_DB)
  File "denoising.py", line 26, in deep_jscc_testing
    noisy_latent = model.encode_through_channel(images, snr_db)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 326, in encode_through_channel
    latent_signal = self.encode(x)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 280, in encode
    h = self.encoder(x)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 453, in forward
    h = self.mid.block_2(h, temb)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 130, in forward
    h = self.norm2(h)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/normalization.py", line 245, in forward
    return F.group_norm(
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/functional.py", line 2111, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps,
RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 44.40 GiB total capacity; 43.08 GiB already allocated; 5.25 MiB free; 43.17 GiB reserved in total by PyTorch)
Loading model from /nfs/turbo/coe-hunseok/ashri/lsun_data/loggings/jscc_models_finetune/snr_0/2023-06-30T10-45-32_jscc_64x64x3/checkpoints/last.ckpt
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 3, 64, 64) = 12288 dimensions.
making attention of type 'vanilla' with 512 in_channels
Loading model from models/ldm/lsun_beds256/autoencoder.ckpt...
Total Params: 55298182
Total Trainable Params: 32961286
  0%|          | 0/75 [00:00<?, ?it/s]  1%|▏         | 1/75 [00:10<12:28, 10.12s/it]  3%|▎         | 2/75 [00:17<10:28,  8.61s/it]  4%|▍         | 3/75 [00:25<09:55,  8.27s/it]  5%|▌         | 4/75 [00:33<09:36,  8.12s/it]  7%|▋         | 5/75 [00:41<09:24,  8.06s/it]  8%|▊         | 6/75 [00:49<09:20,  8.13s/it]  9%|▉         | 7/75 [00:57<08:59,  7.94s/it] 11%|█         | 8/75 [01:05<08:50,  7.92s/it] 12%|█▏        | 9/75 [01:13<08:43,  7.93s/it] 13%|█▎        | 10/75 [01:20<08:34,  7.91s/it] 15%|█▍        | 11/75 [01:28<08:26,  7.92s/it] 16%|█▌        | 12/75 [01:36<08:18,  7.91s/it] 17%|█▋        | 13/75 [01:44<08:11,  7.93s/it] 19%|█▊        | 14/75 [01:52<08:02,  7.91s/it] 20%|██        | 15/75 [02:00<08:02,  8.04s/it] 21%|██▏       | 16/75 [02:09<08:00,  8.15s/it] 23%|██▎       | 17/75 [02:18<08:11,  8.48s/it] 24%|██▍       | 18/75 [02:26<07:54,  8.32s/it] 25%|██▌       | 19/75 [02:34<07:38,  8.18s/it] 27%|██▋       | 20/75 [02:42<07:26,  8.11s/it] 28%|██▊       | 21/75 [02:50<07:20,  8.15s/it] 29%|██▉       | 22/75 [02:58<07:02,  7.97s/it] 31%|███       | 23/75 [03:05<06:53,  7.94s/it] 32%|███▏      | 24/75 [03:13<06:45,  7.94s/it] 33%|███▎      | 25/75 [03:21<06:37,  7.94s/it] 35%|███▍      | 26/75 [03:29<06:27,  7.92s/it] 36%|███▌      | 27/75 [03:37<06:19,  7.91s/it] 37%|███▋      | 28/75 [03:45<06:12,  7.92s/it] 39%|███▊      | 29/75 [03:53<06:03,  7.89s/it] 40%|████      | 30/75 [04:01<06:00,  8.01s/it] 41%|████▏     | 31/75 [04:09<05:46,  7.87s/it] 43%|████▎     | 32/75 [04:17<05:38,  7.87s/it] 44%|████▍     | 33/75 [04:24<05:25,  7.76s/it] 45%|████▌     | 34/75 [04:32<05:18,  7.78s/it] 47%|████▋     | 35/75 [04:39<05:08,  7.71s/it] 48%|████▊     | 36/75 [04:48<05:06,  7.86s/it] 49%|████▉     | 37/75 [04:55<04:55,  7.77s/it] 51%|█████     | 38/75 [05:03<04:48,  7.81s/it] 52%|█████▏    | 39/75 [05:11<04:41,  7.83s/it] 52%|█████▏    | 39/75 [05:11<04:47,  7.99s/it]
Traceback (most recent call last):
  File "denoising.py", line 183, in <module>
    reconstructed = deep_jscc_testing(jscc_model, images, SNR_DB)
  File "denoising.py", line 26, in deep_jscc_testing
    noisy_latent = model.encode_through_channel(images, snr_db)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 326, in encode_through_channel
    latent_signal = self.encode(x)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 280, in encode
    h = self.encoder(x)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 453, in forward
    h = self.mid.block_2(h, temb)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 130, in forward
    h = self.norm2(h)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/normalization.py", line 245, in forward
    return F.group_norm(
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/functional.py", line 2111, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps,
RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 44.40 GiB total capacity; 43.08 GiB already allocated; 5.25 MiB free; 43.17 GiB reserved in total by PyTorch)
Loading model from /nfs/turbo/coe-hunseok/ashri/lsun_data/loggings/jscc_models_finetune/snr_0/2023-06-30T10-45-32_jscc_64x64x3/checkpoints/last.ckpt
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 3, 64, 64) = 12288 dimensions.
making attention of type 'vanilla' with 512 in_channels
Loading model from models/ldm/lsun_beds256/autoencoder.ckpt...
Total Params: 55298182
Total Trainable Params: 32961286
  0%|          | 0/75 [00:00<?, ?it/s]  1%|▏         | 1/75 [00:10<12:31, 10.16s/it]  3%|▎         | 2/75 [00:18<10:45,  8.84s/it]  4%|▍         | 3/75 [00:26<10:15,  8.55s/it]  5%|▌         | 4/75 [00:33<09:39,  8.17s/it]  7%|▋         | 5/75 [00:41<09:24,  8.07s/it]  8%|▊         | 6/75 [00:50<09:21,  8.13s/it]  9%|▉         | 7/75 [00:57<09:01,  7.96s/it] 11%|█         | 8/75 [01:05<08:50,  7.92s/it] 12%|█▏        | 9/75 [01:13<08:50,  8.04s/it] 13%|█▎        | 10/75 [01:21<08:39,  8.00s/it] 15%|█▍        | 11/75 [01:29<08:31,  7.99s/it] 16%|█▌        | 12/75 [01:37<08:20,  7.94s/it] 17%|█▋        | 13/75 [01:45<08:17,  8.03s/it] 19%|█▊        | 14/75 [01:53<08:14,  8.11s/it] 20%|██        | 15/75 [02:01<07:57,  7.96s/it] 21%|██▏       | 16/75 [02:09<07:56,  8.08s/it] 23%|██▎       | 17/75 [02:17<07:45,  8.03s/it] 24%|██▍       | 18/75 [02:26<07:42,  8.12s/it] 25%|██▌       | 19/75 [02:34<07:29,  8.04s/it] 27%|██▋       | 20/75 [02:42<07:27,  8.13s/it] 28%|██▊       | 21/75 [02:50<07:22,  8.19s/it] 29%|██▉       | 22/75 [02:58<07:04,  8.02s/it] 31%|███       | 23/75 [03:06<06:54,  7.97s/it] 32%|███▏      | 24/75 [03:14<06:46,  7.96s/it] 33%|███▎      | 25/75 [03:22<06:36,  7.94s/it] 35%|███▍      | 26/75 [03:29<06:28,  7.93s/it] 36%|███▌      | 27/75 [03:37<06:20,  7.93s/it] 37%|███▋      | 28/75 [03:46<06:18,  8.06s/it] 39%|███▊      | 29/75 [03:53<06:03,  7.90s/it] 40%|████      | 30/75 [04:01<05:55,  7.89s/it] 41%|████▏     | 31/75 [04:09<05:47,  7.91s/it] 43%|████▎     | 32/75 [04:17<05:39,  7.90s/it] 44%|████▍     | 33/75 [04:24<05:26,  7.77s/it] 45%|████▌     | 34/75 [04:32<05:19,  7.79s/it] 47%|████▋     | 35/75 [04:40<05:13,  7.83s/it] 48%|████▊     | 36/75 [04:48<05:10,  7.96s/it] 49%|████▉     | 37/75 [04:56<04:58,  7.85s/it] 51%|█████     | 38/75 [05:04<04:50,  7.86s/it] 52%|█████▏    | 39/75 [05:12<04:43,  7.87s/it] 52%|█████▏    | 39/75 [05:12<04:48,  8.02s/it]
Traceback (most recent call last):
  File "denoising.py", line 183, in <module>
    reconstructed = deep_jscc_testing(jscc_model, images, SNR_DB)
  File "denoising.py", line 26, in deep_jscc_testing
    noisy_latent = model.encode_through_channel(images, snr_db)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 326, in encode_through_channel
    latent_signal = self.encode(x)
  File "/home/ashri/latent-diffusion/ldm/models/autoencoder.py", line 280, in encode
    h = self.encoder(x)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 453, in forward
    h = self.mid.block_2(h, temb)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/latent-diffusion/ldm/modules/diffusionmodules/model.py", line 130, in forward
    h = self.norm2(h)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/normalization.py", line 245, in forward
    return F.group_norm(
  File "/home/ashri/.conda/envs/ldm/lib/python3.8/site-packages/torch/nn/functional.py", line 2111, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps,
RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 44.40 GiB total capacity; 43.08 GiB already allocated; 5.25 MiB free; 43.17 GiB reserved in total by PyTorch)
