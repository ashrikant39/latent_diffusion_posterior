{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caba2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "from scripts.sample_diffusion import *\n",
    "import argparse, os, sys, glob, datetime, yaml\n",
    "from omegaconf import OmegaConf\n",
    "import torchvision\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torchmetrics.functional import psnr, multiscale_structural_similarity_index_measure\n",
    "from torchvision.transforms.functional import pil_to_tensor, to_pil_image\n",
    "from ldm_testing import *\n",
    "from jscc_baseline_testing import deep_jscc_testing\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from ldm_testing import compute_metrics\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7052824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 25 15:46:27 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA A40                      On | 00000000:23:00.0 Off |                    0 |\r\n",
      "|  0%   26C    P8               27W / 300W|      0MiB / 46068MiB |      0%   E. Process |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb323dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_snr_dB = 10\n",
    "test_snr_ratio = 10**(test_snr_dB/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c338e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDiffusionPosteriorJSCC: Running in eps-prediction mode\n",
      "DiffusionWrapper has 274.06 M params.\n",
      "Keeping EMAs of 370.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Loading model from models/ldm/lsun_beds256/autoencoder.ckpt...\n",
      "Total Params: 55298206\n",
      "Total Trainable Params: 55298206\n",
      "Training LatentDiffusionPosteriorJSCC as an unconditional model.\n"
     ]
    }
   ],
   "source": [
    "config = OmegaConf.load(\"/home/ashri/latent-diffusion/configs/latent-diffusion/ldm_all_models_iterative.yaml\")\n",
    "config.model.params.channel_snr_dB = test_snr_dB\n",
    "\n",
    "ldm_posterior_model = instantiate_from_config(config[\"model\"])\n",
    "ldm_posterior_model = ldm_posterior_model.to(\"cuda\")\n",
    "# ldm_posterior_model, _ = load_model(config, checkpoint_path,True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd768f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"post_exp_metrics\"\n",
    "data_fraction = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96252a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/tmpssd/ashri/LSUN/\"\n",
    "val_txt_path = os.path.join(root_dir, \"bedrooms_val.txt\")\n",
    "val_data_dir = os.path.join(root_dir, \"bedrooms\")\n",
    "config.data.params.validation.params.txt_file = val_txt_path\n",
    "config.data.params.validation.params.data_root = val_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ac1a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = instantiate_from_config(config.data.params.validation)\n",
    "seed_generator = torch.Generator().manual_seed(42)\n",
    "random_indices = random.sample(range(main_dataset.__len__()), int(data_fraction*main_dataset.__len__()))\n",
    "dataset = Subset(main_dataset, random_indices)\n",
    "dataloader = DataLoader(dataset, batch_size = 2, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3972e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ec67cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x:torch.tensor):\n",
    "    return (x - x.min())/(x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06c10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_function = lambda img: (2*img - 1.0)\n",
    "ScaleShiftTransform = torchvision.transforms.Lambda(scale_function)\n",
    "data_transform = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc6ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict = {\n",
    "        \"PSNR\": 0.0,\n",
    "        \"MS_SSIM\": 0.0,\n",
    "        \"FID\": 0.0,\n",
    "        \"LPIPS_VGG\": 0.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811197c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 208/250 [2:13:27<25:47, 36.85s/it]  "
     ]
    }
   ],
   "source": [
    "total_examples = dataset.__len__()\n",
    "\n",
    "for image_dict in tqdm(dataloader):\n",
    "    \n",
    "    images = rearrange(image_dict[\"image\"].cuda(), 'b h w c -> b c h w')\n",
    "    codewords = ldm_posterior_model.first_stage_model.encode(images)\n",
    "    signal_power = torch.mean(codewords**2)\n",
    "    noisy_codeword = codewords + torch.randn_like(codewords)*signal_power/test_snr_ratio\n",
    "    sampled_codeword = ldm_posterior_model.posterior_sampling(test_snr_dB, noisy_codeword)\n",
    "    \n",
    "    reconstructed = torch.clamp(ldm_posterior_model.first_stage_model.decode(sampled_codeword), -1.0, 1.0)\n",
    "    scores = compute_metrics(images, reconstructed)\n",
    "    for idx, key in enumerate(metric_dict.keys()):\n",
    "            metric_dict[key] += scores[idx]\n",
    "\n",
    "for key in metric_dict.keys():\n",
    "    metric_dict[key] = metric_dict[key]/total_examples\n",
    "\n",
    "filename = os.path.join(LOGDIR, f\"posterior_test_{test_snr_dB}_metrics.pkl\")\n",
    "\n",
    "with open(filename, \"wb\") as fp:\n",
    "    pickle.dump(metric_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500ca39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codeword = ldm_posterior_model.first_stage_model.encode(tensor_image)\n",
    "# signal_power = torch.mean(codeword**2)\n",
    "# noisy_codeword = codeword + torch.randn_like(codeword)*signal_power/test_snr_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28675148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_codeword = ldm_posterior_model.posterior_sampling(test_snr_dB, noisy_codeword, scale_grad = 2.0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42dee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recon = ldm_posterior_model.first_stage_model.decode(sampled_codeword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recon_image = (custom_to_pil(recon[0]))\n",
    "# recon_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc53c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recon_image.save(\"recon_prior2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7888b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# psnr(normalize(recon[0]), 0.5*(tensor_image[0]+1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6fb288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "ldm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
